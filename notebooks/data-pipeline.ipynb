{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fe68a8c-7bfa-4aac-a1b1-08e5a4dd58e7",
   "metadata": {},
   "source": [
    "## Event Detection\n",
    "\n",
    "This notebooks shows an example of analysis on an MD LJ system using `dupin`.\n",
    "We will use Minkowski structure metrics and the Voronoi polytope volumes for features.\n",
    "The notebook will go through the entire data generation pipeline. In addition, we will\n",
    "showcase the logging infrastructure which looks into the data generation to recover\n",
    "the region of the simulation where nucleation occurs.\n",
    "\n",
    "### Import All the Things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4c6b84-e2e3-4869-90b0-8a16e6f39e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import freud  # analysis toolkit\n",
    "import gsd.fl  # trajectory reader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ruptures as rpt  # change point detection library\n",
    "import scipy as sp\n",
    "import sklearn as sk\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import dupin as du\n",
    "\n",
    "FILENAME = \"lj-sim.gsd\"\n",
    "FRAMES = range(3, 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13339b0-264c-4cf5-92d4-8c2700ddef29",
   "metadata": {},
   "source": [
    "## Generate the Data\n",
    "\n",
    "### Data Definition\n",
    "\n",
    "`dupin` data generation follows a pipeline approach which is most clearly\n",
    "seen with decorators. Below we create a `steinhardt_generator` which will compute the\n",
    "Minkowski structure metrics (MSM) -- the Steinhardt class with `weighted=True` and\n",
    "using a Voronoi neighbor list computes MSM. We use the function `data_generator` to\n",
    "add the Voronoi polytope volume to the feature dictionary of `steinhardt_generator`.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    <p><strong>Note:</strong></p>\n",
    "    <p>\n",
    "        Since we will use the <code>freud.locality.Voronoi</code> object to provide the neighbor list,\n",
    "        the volumes will be up to date in `data_generator`.\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "We then use `DataMap` and `DataReducer` subclasses to get the tenth and first highest/lowest\n",
    "spatially averaged value for each feature.\n",
    "\n",
    "In the next cell we set up some base objects, and then show two methods for creating our final data\n",
    "pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaa4926-d067-4790-a519-9dc6daab11c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = [2, 4, 6, 8, 10]\n",
    "steinhardt_compute = freud.order.Steinhardt(l=ls, weighted=True)\n",
    "voronoi_nlist_generator = freud.locality.Voronoi()\n",
    "\n",
    "steinhardt_generator = du.data.freud.FreudDescriptor(\n",
    "    compute=steinhardt_compute, attrs={\"particle_order\": [f\"$Q_{{{i}}}$\" for i in ls]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb7b332-392e-4060-b518-3433da92a710",
   "metadata": {},
   "source": [
    "### Decorator Method\n",
    "\n",
    "The decorator method uses the `wraps()` method to create something that works\n",
    "appropriately as a decorator for all builtin classes for data generator and\n",
    "manipulation in `dupin`. This approach goes from bottom to top as\n",
    "decorators in Python always do. That means the top-most decorator is the last\n",
    "in the pipeline. This method can be useful when using a custom function to\n",
    "generate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4243736-ab4e-4064-9c04-7d014c6ba607",
   "metadata": {},
   "outputs": [],
   "source": [
    "@du.data.reduce.NthGreatest.wraps([1, 10, -1, -10])\n",
    "@du.data.map.Tee.wraps(\n",
    "    [\n",
    "        du.data.spatial.NeighborAveraging.wraps(\"neighbors\", False),\n",
    "        du.data.map.Identity.wraps(),\n",
    "    ]\n",
    ")\n",
    "def data_generator(\n",
    "    system: \"tuple[freud.box.Box, np.ndarray[float]]\",\n",
    "    neighbors: \"freud.locality.NeighborList\",\n",
    "):\n",
    "    \"\"\"Combine the MSM and Voronoi polytope volumes.\"\"\"\n",
    "    data = steinhardt_generator(system, neighbors=neighbors)\n",
    "    data[\"$V_{vor}$\"] = voronoi_nlist_generator.volumes\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce3ba9e-ae03-4ff2-80d5-29afec2c62b7",
   "metadata": {},
   "source": [
    "### Pipeline Method\n",
    "\n",
    "Another way to build the final data pipeline is through a pipeline\n",
    "syntax. This approach still uses `wraps` which is necessary to create\n",
    "the pipeline all at once, but the approach is to go left to right\n",
    "in the data manipulation process which can appear more natural to many\n",
    "people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80681c0f-149c-4839-8f4e-faff265a7021",
   "metadata": {},
   "outputs": [],
   "source": [
    "@du.data.base.CustomGenerator\n",
    "def data_generator(\n",
    "    system: \"tuple[freud.box.Box, np.ndarray[float]]\",\n",
    "    neighbors: \"freud.locality.NeighborList\",\n",
    "):\n",
    "    \"\"\"Combine the MSM and Voronoi polytope volumes.\"\"\"\n",
    "    data = steinhardt_generator(system, neighbors=neighbors)\n",
    "    data[\"$V_{vor}$\"] = voronoi_nlist_generator.volumes\n",
    "    return data\n",
    "\n",
    "\n",
    "data_generator = data_generator.pipe(\n",
    "    du.data.map.Tee.wraps(\n",
    "        [\n",
    "            du.data.spatial.NeighborAveraging.wraps(\"neighbors\", False),\n",
    "            du.data.map.Identity.wraps(),\n",
    "        ]\n",
    "    )\n",
    ").pipe(du.data.reduce.NthGreatest.wraps([1, 100, -1, -100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59b9b57-ea42-4f04-aa86-2f837a60be2a",
   "metadata": {},
   "source": [
    "### Data Computation\n",
    "\n",
    "Wrap the generator into a `SignalAggregator` object\n",
    "to enable collection of the feature set across the trajectory.\n",
    "We also specify, a logger to record information throughout the pipeline.\n",
    "Given the many layers to the pipeline, simply providing properties for the\n",
    "different objects would be more cumbersome, so we just listen into the pipeline\n",
    "using the logging system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523397bd-09d6-4eea-bf3b-56c57ac4fe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_aggregator = du.data.SignalAggregator(data_generator, du.data.logging.Logger())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8de7f3-8606-4ef4-b4f5-17326a4d4f5b",
   "metadata": {},
   "source": [
    "Let's actually compute the features now, and get a\n",
    "`pandas.DataFrame` object to work with and view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ab0a54-5d5c-4628-868f-4ad41e3ff482",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gsd.fl.open(FILENAME, \"rb\") as traj:\n",
    "    for frame in FRAMES:\n",
    "        system = (\n",
    "            traj.read_chunk(frame, \"configuration/box\"),\n",
    "            traj.read_chunk(frame, \"particles/position\"),\n",
    "        )\n",
    "        voronoi_nlist_generator.compute(system)\n",
    "        signal_aggregator.accumulate(\n",
    "            system, neighbors=voronoi_nlist_generator.nlist\n",
    "        )\n",
    "df = signal_aggregator.to_dataframe()\n",
    "df.to_hdf(\"./lj-data.h5\", \"data\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3edf584-dd1d-422f-aa38-a6156c4b1ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df = signal_aggregator.logger.to_dataframe()\n",
    "log_df.to_hdf(\"./lj-log.h5\", \"data\")\n",
    "log_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeae428-92a4-4af3-bda7-6509fdcd73ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def position_generator(filename, frames):\n",
    "    with gsd.fl.open(filename, \"rb\") as fh:\n",
    "        for frame in frames:\n",
    "            yield fh.read_chunk(frame, \"particles/position\")\n",
    "\n",
    "\n",
    "f_positions = du.postprocessing.retrieve_positions(\n",
    "    log_df, position_generator(FILENAME, FRAMES)\n",
    ")\n",
    "f_positions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdafc6b9-c126-4201-9758-911f51d31fd5",
   "metadata": {},
   "source": [
    "### Find Rough Nucleation Region\n",
    "\n",
    "Using the recovered positions we will find the area of the simulation where nucleation\n",
    "occurs. This uses the knowlegde that nucleation occurs arround the 14th frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3a48e9-2568-4e64-b74b-4bf637b8b7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "nucl_positions = f_positions[\"$Q_{6}$\"][\"NthGreatest\"][\"100th_greatest\"].iloc[14:18]\n",
    "mean_pos = nucl_positions.mean().to_numpy()\n",
    "std_pos = nucl_positions.std().to_numpy()\n",
    "print(f\"Nucleation likely around {mean_pos} with standard deviation {std_pos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7a8392-8419-4e59-9ce8-b53294054c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "nucl_positions = f_positions[\"$Q_{6}$\"][\"NthGreatest\"][\"100th_greatest\"].iloc[14]\n",
    "print(f\"Nucleation location {nucl_positions.to_numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb57784-91e7-4a1d-a573-1b8a119f4aaa",
   "metadata": {},
   "source": [
    "## Computing array features for later analysis\n",
    "\n",
    "`SignalAggregator` can also be used to aggregate per-particle features \n",
    "and convert the data to an `xarray.DataArray` object. Notice how we\n",
    "do not reduce the array data in the pipeline below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90262e4c-4758-4409-98b7-3ff425b8a9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@du.data.base.CustomGenerator\n",
    "def data_generator(\n",
    "    system: \"tuple[freud.box.Box, np.ndarray[float]]\",\n",
    "    neighbors: \"freud.locality.NeighborList\",\n",
    "):\n",
    "    \"\"\"Combine the MSM and Voronoi polytope volumes.\"\"\"\n",
    "    data = steinhardt_generator(system, neighbors=neighbors)\n",
    "    data[\"$V_{vor}$\"] = voronoi_nlist_generator.volumes\n",
    "    return data\n",
    "\n",
    "\n",
    "data_generator = data_generator.pipe(\n",
    "    du.data.map.Tee.wraps(\n",
    "        [\n",
    "            du.data.spatial.NeighborAveraging.wraps(\"neighbors\", False),\n",
    "            du.data.map.Identity.wraps(),\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1534265f-ac10-44b4-bf52-c1da50b32837",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_aggregator = du.data.SignalAggregator(data_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ef85e1-c80f-4847-a7e0-0f92d94aefac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gsd.fl.open(FILENAME, \"rb\") as traj:\n",
    "    for frame in tqdm(FRAMES):\n",
    "        system = (\n",
    "            traj.read_chunk(frame, \"configuration/box\"),\n",
    "            traj.read_chunk(frame, \"particles/position\"),\n",
    "        )\n",
    "        voronoi_nlist_generator.compute(system)\n",
    "        signal_aggregator.accumulate(\n",
    "            system, neighbors=voronoi_nlist_generator.nlist\n",
    "        )\n",
    "xarr = signal_aggregator.to_xarray(third_dim_name=\"particle\")\n",
    "xarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452dfd6e-f401-4c57-bf8d-56b32f8c895b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Research (conda)",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
